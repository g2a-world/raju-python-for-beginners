{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validate Mongodb Database Setup\n",
    "* Overview of Scrapy Pipelines\n",
    "* Overview of using hash code for quote text\n",
    "* Update Spider Logic to include hash code\n",
    "* Develop Pipeline Logic to write to Mongodb\n",
    "* Run the Pipeline to write to Mongodb\n",
    "* Validate Data in Mongodb Collection\n",
    "* Exercise and Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validate Mongodb Database Setup\n",
    "\n",
    "1. Make sure Mongodb is running (Use telnet to validate - `telnet localhost 27017`)\n",
    "2. Launch Mongo shell using `mongosh`.\n",
    "3. We can also use `pymongo` to connect to Mongodb Database using Python.\n",
    "\n",
    "```python\n",
    "import pymongo\n",
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "\n",
    "for db in client.list_databases():\n",
    "    print(db['name'])\n",
    "\n",
    "# We can create new database and then use relevant APIs to deal with collections and documents\n",
    "db = client['quotes_db']\n",
    "\n",
    "# If the database is empty, you will not see any collections\n",
    "for collection in db.list_collections():\n",
    "    print(collection)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Overview of Scrapy Pipelines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Overview of using hash code for quote text\n",
    "\n",
    "```python\n",
    "import hashlib\n",
    "sha = hashlib.sha256()\n",
    "\n",
    "s = 'Hello World'\n",
    "sha.update(s.encode())\n",
    "\n",
    "sha.hexdigest()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Update Spider Logic to include hash code\n",
    "\n",
    "```python\n",
    "import hashlib\n",
    "import scrapy\n",
    "\n",
    "\n",
    "def generate_urls(base_url):\n",
    "    urls = []\n",
    "    for i in range(1, 101):\n",
    "        urls.append(f'{base_url}?page={i}')\n",
    "    return urls\n",
    "\n",
    "    \n",
    "class QuoteSpider(scrapy.Spider):\n",
    "    name = 'quotes'\n",
    "    start_urls = generate_urls('https://www.goodreads.com/quotes')\n",
    "\n",
    "    def parse(self, response):\n",
    "        sha = hashlib.sha256()\n",
    "        for quoteDetails in response.css('.quoteDetails'):\n",
    "            quote_text = quoteDetails.css('.quoteText::text').get()\n",
    "            sha.update(quote_text.encode())\n",
    "            payload = {\n",
    "                'quoteTextHash': sha.hexdigest(),\n",
    "                'quoteText': quote_text,\n",
    "                'authorOrTitle': quoteDetails.css('span.authorOrTitle::text').get(),\n",
    "                'authorOrTitleUrl': quoteDetails.css('a.authorOrTitle::attr(href)').get(),\n",
    "                'authorOrTitleText': quoteDetails.css('a.authorOrTitle::text').get()\n",
    "            }\n",
    "            yield payload\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Develop Pipeline Logic to write to Mongodb\n",
    "\n",
    "```python\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
