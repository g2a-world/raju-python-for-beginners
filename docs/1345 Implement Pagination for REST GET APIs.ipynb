{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Overview of Pagination\n",
    "* Additional Parameters and Attributes for Pagination\n",
    "* Add Pagination to users API\n",
    "* Validate users API with Pagination\n",
    "* Process all the users data using Pagination\n",
    "* Exercise and Solution - Pagination for orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before getting started make sure to reset the database tables\n",
    "# Login to flask shell and run db.drop_all() and db.create_all()\n",
    "\n",
    "# Generate Fake Data for users\n",
    "from faker import Faker\n",
    "faker = Faker()\n",
    "users = []\n",
    "usernames = set()\n",
    "ctr = 0\n",
    "\n",
    "while True:\n",
    "    if ctr == 10000:\n",
    "        break\n",
    "    first_name = faker.first_name()\n",
    "    last_name = faker.last_name()\n",
    "    username = f'{first_name[:1]}{last_name}'.lower()\n",
    "    email = f'{username}@email.com'\n",
    "    if username not in usernames:\n",
    "        usernames.add(username)\n",
    "        user = {\n",
    "            'id': '',\n",
    "            'first_name': first_name,\n",
    "            'last_name': last_name,\n",
    "            'username': username,\n",
    "            'email': email\n",
    "        }\n",
    "        users.append(user)\n",
    "        ctr = ctr + 1\n",
    "\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = input('Enter base url: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(input('Enter batch size: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(users), batch_size):\n",
    "    users_chunk = users[i:i+batch_size]\n",
    "    response = requests.post(\n",
    "        f'{base_url}/users', \n",
    "        data={'users': json.dumps(users_chunk)}\n",
    "    )\n",
    "    print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Overview of Pagination\n",
    "\n",
    "We need to paginate the results, if the API is expected to return bulk data.\n",
    "1. If we do not paginate, the request might run into resource contention as the resultset size grow big.\n",
    "2. Pagination will result in multiple API calls. Each call will return the number of records based on the page size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Additional Parameters and Attributes for Pagination\n",
    "\n",
    "While implementing pagination, we consider additional parameters and attributes as part of the results.\n",
    "\n",
    "1. `pageSize` - the maximum number of records each page should contain. It is both an attribute and parameter. Based on the parameter value, the maximum number of records should be returned.\n",
    "2. `pageToken` - the token based on which next set of records should be fetched. It is typically the last value of primary key or unique key value in each API call.\n",
    "\n",
    "Note: If `pageToken` is not passed, then we will fetch the first set of results based on `pageSize`. The result will contain `pageToken` only if we have the number of records equivalent to `pageSize`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add Pagination to users API\n",
    "\n",
    "Update `users()` for GET API with following pagination logic. It takes care of the following:\n",
    "\n",
    "1. Use parameters such as `pageToken` and `pageSize`.\n",
    "2. Apply `pageSize` with threshold (let's say 100 is the max for `pageSize`).\n",
    "3. Ensure data is sorted and `pageToken` is computed. `pageToken` is nothing but last `id` in the result set.\n",
    "4. In case the record count is less than `pageSize`, `pageToken` should not be returned.\n",
    "5. Make sure to update doc string with additional parameters so that they are reflected in apidocs.\n",
    "\n",
    "```python\n",
    "@app.route('/users')\n",
    "def users():\n",
    "    \"\"\"\n",
    "    Retrieve users\n",
    "    ---\n",
    "    parameters:\n",
    "      - name: email\n",
    "        in: query\n",
    "        type: string\n",
    "        required: false\n",
    "      - name: pageSize\n",
    "        in: query\n",
    "        type: integer\n",
    "        required: false\n",
    "      - name: pageToken\n",
    "        in: query\n",
    "        type: integer\n",
    "        required: false\n",
    "    responses:\n",
    "      200:\n",
    "        description: Users retrieved successfully\n",
    "    \"\"\"\n",
    "    page_token = int(request.args.get('pageToken')) if request.args.get('pageToken') else None\n",
    "    search_email = request.args.get('email', '')\n",
    "    page_size = int(request.args.get('pageSize')) \\\n",
    "        if request.args.get('pageSize') and int(request.args.get('pageSize')) <= 100 \\\n",
    "        else 25\n",
    "\n",
    "    if search_email:\n",
    "        # Query the database and filter users based on the pattern match\n",
    "        if page_token:\n",
    "            user_recs = db.session.query(User).filter(User.email.like(f'{search_email.lower()}%')).filter(User.id > page_token).order_by(User.id).limit(page_size).all()\n",
    "        else:\n",
    "            user_recs = db.session.query(User).filter(User.email.like(f'{search_email.lower()}%')).order_by(User.id).limit(page_size).all()\n",
    "    else:\n",
    "        # Retrieve all users if no search query is provided\n",
    "        if page_token:\n",
    "            user_recs = db.session.query(User).filter(User.id > page_token).order_by(User.id).limit(page_size).all()\n",
    "        else: \n",
    "            user_recs = db.session.query(User).order_by(User.id).limit(page_size).all()\n",
    "\n",
    "    # below code throws error as the SQL Alchemy get response includes attributes\n",
    "    # such as _sa_instance_state. \n",
    "    # The values of these attributes are not JSON Serializable\n",
    "    # users = list(map(lambda rec: rec.__dict__, user_recs))\n",
    "    users = []\n",
    "    for user in user_recs:\n",
    "        user.__dict__.pop('_sa_instance_state')\n",
    "        users.append(user.__dict__)\n",
    "\n",
    "    payload = {\n",
    "        'records': users,\n",
    "        'pageToken': users[-1]['id'] if len(users) == page_size else None,\n",
    "        'recordCount': len(users)\n",
    "    }\n",
    "    return jsonify(payload)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validate users API with Pagination\n",
    "\n",
    "1. Go to `/apidocs`\n",
    "2. Test multiple scenarios (`/users` with out page size, with page size, with page size and token, etc)\n",
    "\n",
    "You can also use `requests` to validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = input('Enter base url: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(f'{base_url}/users').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(f'{base_url}/users?pageSize=100').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(f'{base_url}/users?pageToken=100&pageSize=100').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(f'{base_url}/users?pageSize=101').json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Process all the users data using Pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = input('Enter base url: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "pageToken = 0\n",
    "pageSize = 100\n",
    "while True:\n",
    "    payload = requests.get(f'{base_url}/users?pageSize={pageSize}&pageToken={pageToken}').json()\n",
    "    users.extend(payload['records'])\n",
    "    if payload['recordCount'] < pageSize:\n",
    "        break\n",
    "    pageToken = payload['records'][-1]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exercise - Pagination for orders\n",
    "\n",
    "1. Make sure to populate orders data into the table (using POST API on orders).\n",
    "2. Update `/orders` logic with pagination. Make sure it accept both `pageSize` and `pageToken` as parameters. The default `pageSize` should be 100 and the maximum `pageSize` can go up to 1000. In case, if the `pageSize` is greater than 1000, then it should return only 1000 records, otherwise the API should return the number of records equivalent to specified page size. You can use Chat GPT to generate the code by passing users code as reference.\n",
    "3. Validate if pagination logic is working as expected or not. Here are some of the test case scenarios.\n",
    "  * Invoke `/orders` without token or size. It should return 100 records.\n",
    "  * Invoke `/orders` with page size 500 and token 500. It should return 500 records starting from order id 501.\n",
    "  * Invoke `/orders` with page size 1001 and token 500. It should return 1000 records starting from 501.\n",
    "4. Come up with required logic to process all the orders. Start with page token 0 and page size 1000.\n",
    "5. Make sure to deploy the changes on to Remote VM using GitHub Action. Go to API Docs and validate to see if the end point is reflected or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Solution - Pagination for orders\n",
    "\n",
    "1. Make sure to populate orders data into the table (using POST API on orders).\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import json\n",
    "\n",
    "base_url = input('Enter base url: ')\n",
    "batch_size = int(input('Enter batch size (eg: 10000): '))\n",
    "\n",
    "for i in range(0, len(orders), batch_size):\n",
    "    orders_chunk = orders[i:i+batch_size]\n",
    "    response = requests.post(\n",
    "        f'{base_url}/orders', \n",
    "        data={'orders': json.dumps(orders_chunk)}\n",
    "    )\n",
    "    print(response.status_code)\n",
    "```\n",
    "\n",
    "2. Update `/orders` logic with pagination. Make sure it accept both `pageSize` and `pageToken` as parameters. The default `pageSize` should be 100 and the maximum `pageSize` can go up to 1000. In case, if the `pageSize` is greater than 1000, then it should return only 1000 records, otherwise the API should return the number of records equivalent to specified page size. You can use Chat GPT to generate the code by passing users code as reference.\n",
    "\n",
    "```python\n",
    "@app.route('/orders')\n",
    "def orders():\n",
    "    \"\"\"\n",
    "    Retrieve orders\n",
    "    ---\n",
    "    parameters:\n",
    "      - name: pageSize\n",
    "        in: query\n",
    "        type: integer\n",
    "        required: false\n",
    "      - name: pageToken\n",
    "        in: query\n",
    "        type: integer\n",
    "        required: false\n",
    "    responses:\n",
    "      200:\n",
    "        description: Orders retrieved successfully\n",
    "    \"\"\"\n",
    "    page_token = int(request.args.get('pageToken')) if request.args.get('pageToken') else None\n",
    "    page_size = int(request.args.get('pageSize')) \\\n",
    "        if request.args.get('pageSize') and int(request.args.get('pageSize')) <= 1000 \\\n",
    "        else 1000\n",
    "    \n",
    "    if page_token:\n",
    "        order_recs = db.session.query(Order). \\\n",
    "            filter(Order.order_id > page_token). \\\n",
    "            order_by(Order.order_id). \\\n",
    "            limit(page_size). \\\n",
    "            all()\n",
    "    else:\n",
    "        order_recs = db.session.query(Order). \\\n",
    "            order_by(Order.order_id). \\\n",
    "            limit(page_size). \\\n",
    "            all()\n",
    "\n",
    "    orders = []\n",
    "    for order in order_recs:\n",
    "        order.__dict__.pop('_sa_instance_state')\n",
    "        orders.append(order.__dict__)\n",
    "\n",
    "    payload = {\n",
    "        'records': orders,\n",
    "        'pageToken': orders[-1]['order_id'] if len(orders) == page_size else None,\n",
    "        'recordCount': len(orders)\n",
    "    }\n",
    "\n",
    "    return jsonify(payload)\n",
    "```\n",
    "\n",
    "3. Validate if pagination logic is working as expected or not. Here are some of the test case scenarios.\n",
    "  * Invoke `/orders` without token or size. It should return 100 records.\n",
    "  * Invoke `/orders` with page size 500 and token 500. It should return 500 records starting from order id 501.\n",
    "  * Invoke `/orders` with page size 1001 and token 500. It should return 1000 records starting from 501.\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "base_url = input('Enter base url: ')\n",
    "\n",
    "requests.get(f'{base_url}/orders').json()\n",
    "requests.get(f'{base_url}/orders?pageSize=500&pageToken=500').json()\n",
    "requests.get(f'{base_url}/orders?pageSize=1001&pageToken=500').json()\n",
    "```\n",
    "\n",
    "4. Come up with required logic to process all the orders. Start with page token 0 and page size 1000.\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "base_url = input('Enter base url: ')\n",
    "\n",
    "orders = []\n",
    "pageToken = 0\n",
    "pageSize = 100\n",
    "while True:\n",
    "    payload = requests.get(f'{base_url}/orders?pageSize={pageSize}&pageToken={pageToken}').json()\n",
    "    orders.extend(payload['records'])\n",
    "    if payload['recordCount'] < pageSize:\n",
    "        break\n",
    "    pageToken = payload['records'][-1]['id']\n",
    "```\n",
    "\n",
    "5. Make sure to deploy the changes on to Remote VM using GitHub Action. Go to API Docs and validate to see if the end point is reflected or not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
