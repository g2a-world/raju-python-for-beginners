{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validate the installation of Pandas\n",
    "* Understand NFL Data in HTML\n",
    "* Analyze HTML Table Data using Pandas\n",
    "* Limitations of using Pandas HTML APIs\n",
    "* Integration of BeautifulSoup and Pandas\n",
    "* Exercise and Solution - Analyze HTML Data using Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validate the installation of Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip show pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Understand NFL Data in HTML\n",
    "\n",
    "A simple table copied from NFL Wiki - https://en.wikipedia.org/wiki/National_Football_League"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analyze HTML Table Data using Pandas\n",
    "\n",
    "1. Create Pandas Data Frame for HTML Table Data\n",
    "2. Analyze the data in Data Frame using appropriate APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lxml # restart the notebook environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'nfl_teams.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_html(file_name)[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get Division, Club and Head Coach Details\n",
    "2. Get all the Teams related to East\n",
    "3. Get Number of Teams per Conference and Division"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get Division, Club and Head Coach Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_df = pd.read_html(file_name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_df[['Division', 'Club', 'Head Coach']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get all the Teams related to East"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_df.query('Division == \"East\"')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Get Number of Teams per Conference and Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(nfl_df.groupby(['Conference', 'Division'])['Club'].agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_df. \\\n",
    "    groupby(['Conference', 'Division'])['Club']. \\\n",
    "    agg(club_count='count'). \\\n",
    "    reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Limitations of using Pandas HTML APIs\n",
    "\n",
    "Here are the limitations related to using Pandas to analyze HTML data.\n",
    "\n",
    "1. Supports only http, ftp and file url protocols. Hence you might not be able to use secure urls.\n",
    "2. Behavior might not be consistent if the html pages are too diversified (like Wiki pages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Integration of BeautifulSoup and Pandas\n",
    "\n",
    "We will process the data under all the 100 pages under https://www.goodreads.com/quotes\n",
    "\n",
    "1. Parse all the 100 pages.\n",
    "2. Create list of dicts containing quote text, author or title, author or title url and author or title url text.\n",
    "3. Create Data Frame using Pandas\n",
    "4. Analyze the Data based on the requirements (eg: number of quotes per author or title) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "base_url = 'https://www.goodreads.com/quotes'\n",
    "for i in range(1, 101):\n",
    "    urls.append(f'{base_url}?page={i}')\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = requests.get(urls[0]).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.find_all('div', attrs={'class': 'quoteText'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quoteText = soup.find('div', attrs={'class': 'quoteText'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quoteText.find(string=True, recursive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quoteText.find('span').find(string=True, recursive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_or_title_url = None\n",
    "author_or_title_url_text = None\n",
    "\n",
    "if quoteText.find('a'):\n",
    "    author_or_title_url = quoteText.find('a')['href']\n",
    "    author_or_title_url_text = quoteText.find('a').find(string=True, recursive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "quotes = []\n",
    "urls = []\n",
    "\n",
    "base_url = 'https://www.goodreads.com/quotes' \n",
    "for i in range(1, 101):\n",
    "    urls.append(f'{base_url}?page={i}')\n",
    "\n",
    "for url in urls:\n",
    "    print(f'Processing: {url}')\n",
    "    html_content = requests.get(url).content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    quoteTexts = soup.find_all('div', attrs={'class': 'quoteText'})\n",
    "    for quoteText in quoteTexts:\n",
    "        quote_text = quoteText.find(string=True, recursive=False)\n",
    "        author_or_title = None\n",
    "        author_or_title_url = None\n",
    "        author_or_title_url_text = None\n",
    "        if quoteText.find('span'):\n",
    "            author_or_title = quoteText.find('span').find(string=True, recursive=False)\n",
    "        if quoteText.find('a'):\n",
    "            author_or_title_url = quoteText.find('a')['href']\n",
    "            author_or_title_url_text = quoteText.find('a').find(string=True, recursive=False)\n",
    "        quotes.append({\n",
    "            'quote_text': quote_text,\n",
    "            'author_or_title': author_or_title,\n",
    "            'author_or_title_url': author_or_title_url,\n",
    "            'author_or_title_url_text': author_or_title_url_text\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_df = pd.DataFrame(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exercise - Analyze HTML Data using Pandas\n",
    "\n",
    "1. Use the quotes_df above or create one\n",
    "2. Group the data by `author_or_title` and get the count\n",
    "3. Ensure the aggregated data frame have `author_or_title` and `quote_count` (new column for count)\n",
    "4. Sort the data in descending order by values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Solution - Analyze HTML Data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_df. \\\n",
    "    groupby(['author_or_title'])['author_or_title']. \\\n",
    "    agg(quote_count='count'). \\\n",
    "    reset_index(). \\\n",
    "    sort_values('quote_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
